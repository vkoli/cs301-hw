{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Vrushali Ritesh Koli\n",
    "# Date: 2020/02/24\n",
    "# CS301-006, Professor Watson\n",
    "# HW4 Solution\n",
    "# Data manipulation exercise with a coronovirus open dataset\n",
    "# https://github.com/vkoli/cs301-hw\n",
    "# \n",
    "# master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_percent_nans(df, col):\n",
    "    num_rows = df.shape[0]\n",
    "    total_na = df[col].isna().sum()\n",
    "    per = (total_na / num_rows) * 100\n",
    "    return per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The \"Province/State\" column has 24.45% empty values\n",
      "The \"Country/Region\" column has 0.00% empty values\n",
      "The \"Last Update\" column has 0.00% empty values\n",
      "The \"Confirmed\" column has 1.60% empty values\n",
      "The \"Suspected\" column has 95.31% empty values\n",
      "The \"Recovered\" column has 46.67% empty values\n",
      "The \"Death\" column has 53.22% empty values\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"/home/toph/Documents/cs301/2019_nCoV_20200121_20200206.csv\")\n",
    "\n",
    "for col in data_df.columns:\n",
    "    #print(col)\n",
    "    #print(get_percent_nans(data_df, col))\n",
    "    print('The \\\"{}\\\" column has {:.2f}% empty values'.format(col, get_percent_nans(data_df, col)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2\n",
    "According to the data found in the “2019_nCoV_20200121_20200206.csv” file, whichCountry/Region​ has the ​most​ amount of Deaths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country/Region  Death\n",
       "0  Mainland China  479.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only take the country and death column\n",
    "df = data_df[['Country/Region', 'Death']]\n",
    "# Find the country(ies) where the death rate is equal to the max in the column\n",
    "df2 = df[df['Death']==df['Death'].max()].drop_duplicates()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 \n",
    "According to the data found in the “2019_nCoV_20200121_20200206.csv” file, whichCountry/Region​ has the ​highest ​number of suspected cases of 2019 nCoV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Australia': Int64Index([1808], dtype='int64'),\n",
       " 'Brazil': Int64Index([1810], dtype='int64'),\n",
       " 'Colombia': Int64Index([1811], dtype='int64'),\n",
       " 'Hong Kong': Int64Index([1532, 1581, 1623, 1665, 1712, 1748, 1778, 1824, 1871], dtype='int64'),\n",
       " 'Mainland China': Int64Index([1512, 1516, 1518, 1519, 1522, 1527, 1558, 1561, 1563, 1564, 1571,\n",
       "             1576, 1582, 1605, 1606, 1607, 1608, 1613, 1617, 1627, 1648, 1650,\n",
       "             1651, 1652, 1659, 1670, 1675, 1691, 1694, 1696, 1698, 1699, 1700,\n",
       "             1702, 1711, 1718, 1719, 1731, 1734, 1735, 1736, 1739, 1742, 1759,\n",
       "             1766, 1769, 1771, 1774, 1781, 1789, 1790, 1791, 1793, 1812, 1817,\n",
       "             1818, 1822, 1830, 1837, 1839, 1850, 1854, 1855, 1857, 1858, 1860,\n",
       "             1861, 1864, 1865, 1866, 1868, 1869, 1872],\n",
       "            dtype='int64'),\n",
       " 'Malaysia': Int64Index([1806], dtype='int64'),\n",
       " 'Mexico': Int64Index([1809], dtype='int64'),\n",
       " 'Philippines': Int64Index([1805], dtype='int64')}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take the country and suspected column, drop NAN values\n",
    "df = data_df[['Country/Region', 'Suspected']].dropna()\n",
    "# group the rows into countries\n",
    "sorted_df = df.groupby('Country/Region')\n",
    "sorted_df.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country/Region\n",
       "Australia            1.0\n",
       "Brazil               1.0\n",
       "Colombia             1.0\n",
       "Mexico               1.0\n",
       "Malaysia             4.0\n",
       "Philippines          4.0\n",
       "Mainland China     839.0\n",
       "Hong Kong         1139.0\n",
       "Name: Suspected, dtype: float64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum up all the suspected values for each country\n",
    "suspected_df = sorted_df['Suspected'].agg(np.sum)\n",
    "sorted_df = suspected_df.sort_values()\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hong Kong'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df.idxmax()\n",
    "# Answer is Hong Kong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4\n",
    "According to the data found in the “2019_nCoV_20200121_20200206.csv” file, whichCountry/Region​ has the ​second highest ​average number of recovered cases of 2019 nCoV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Australia': Int64Index([ 42,  43,  44,  46, 112, 113, 114, 116, 182, 183, 184, 186, 252,\n",
       "             253, 255, 256, 321, 322, 324, 325, 390, 391, 393, 394, 458, 459,\n",
       "             461, 462, 525, 526, 528, 529, 592, 593, 595, 596, 658, 659, 661,\n",
       "             668, 725, 726, 728, 734, 801, 856, 927, 986],\n",
       "            dtype='int64'),\n",
       " 'Belgium': Int64Index([55, 125, 195], dtype='int64'),\n",
       " 'Cambodia': Int64Index([56, 126, 196, 265, 334, 403, 470, 536, 603, 669, 735], dtype='int64'),\n",
       " 'Canada': Int64Index([ 47,  57,  58, 117, 127, 128, 187, 197, 198, 257, 266, 267, 326,\n",
       "             335, 336, 392, 404, 460, 471, 527, 537, 594, 604, 662, 670, 729,\n",
       "             736],\n",
       "            dtype='int64'),\n",
       " 'Finland': Int64Index([59, 129, 199, 268, 337, 405, 472, 538, 605, 671, 737], dtype='int64'),\n",
       " 'France': Int64Index([40, 110, 180, 250, 319, 387, 455, 522, 589, 656, 723], dtype='int64'),\n",
       " 'Germany': Int64Index([35, 105, 175, 245, 314, 383, 451, 518, 585, 653, 721], dtype='int64'),\n",
       " 'Hong Kong': Int64Index([32, 102, 172, 242, 311, 380, 448, 515, 582, 650, 716], dtype='int64'),\n",
       " 'India': Int64Index([45, 115, 185, 254, 323, 395, 463, 530, 597, 672, 738], dtype='int64'),\n",
       " 'Italy': Int64Index([48, 118, 188, 258, 327, 396, 464, 531, 598, 663, 730], dtype='int64'),\n",
       " 'Japan': Int64Index([  31,  101,  171,  239,  308,  377,  445,  512,  579,  646,  711,\n",
       "              789,  850,  915,  974, 1032, 1087, 1142, 1193, 1245, 1297, 1348,\n",
       "             1400, 1451, 1499, 1545],\n",
       "            dtype='int64'),\n",
       " 'Macau': Int64Index([38, 107, 177, 246, 316, 385, 453, 520, 587, 655, 722], dtype='int64'),\n",
       " 'Mainland China': Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "             ...\n",
       "             1687, 1688, 1689, 1690, 1694, 1728, 1729, 1730, 1771, 1779],\n",
       "            dtype='int64', length=555),\n",
       " 'Malaysia': Int64Index([36, 108, 178, 247, 317, 386, 454, 521, 588, 654, 720], dtype='int64'),\n",
       " 'Nepal': Int64Index([61, 131, 201, 270, 339, 407, 474, 540, 607, 674, 740], dtype='int64'),\n",
       " 'Philippines': Int64Index([49, 119, 189, 259, 328, 397, 465, 532, 599, 664, 741], dtype='int64'),\n",
       " 'Russia': Int64Index([50, 120, 190, 260, 329, 398, 466, 533, 600, 665, 731], dtype='int64'),\n",
       " 'Singapore': Int64Index([29, 100, 170, 241, 310, 379, 447, 514, 581, 648, 715], dtype='int64'),\n",
       " 'South Korea': Int64Index([33, 104, 173, 244, 313, 381, 449, 516, 583, 649, 717], dtype='int64'),\n",
       " 'Spain': Int64Index([62, 132, 202, 271, 340, 408, 475, 541, 608, 675, 742], dtype='int64'),\n",
       " 'Sri Lanka': Int64Index([63, 133, 203, 272, 341, 409, 476, 542, 609, 676, 743, 800], dtype='int64'),\n",
       " 'Sweden': Int64Index([64, 134, 204, 273, 342, 410, 477, 543, 610, 677, 744], dtype='int64'),\n",
       " 'Taiwan': Int64Index([37, 106, 176, 248, 315, 384, 452, 519, 586, 651, 718], dtype='int64'),\n",
       " 'Thailand': Int64Index([  30,   99,  169,  240,  309,  378,  446,  513,  580,  647,  712,\n",
       "              790,  849,  916,  975, 1033, 1088, 1143, 1194, 1246, 1298, 1349,\n",
       "             1401, 1452, 1500, 1546],\n",
       "            dtype='int64'),\n",
       " 'UK': Int64Index([51, 121, 191, 261, 330, 399, 467, 534, 601, 666, 732], dtype='int64'),\n",
       " 'United Arab Emirates': Int64Index([41, 111, 181, 251, 320, 389, 457, 524, 591, 660, 727], dtype='int64'),\n",
       " 'United States': Int64Index([ 52,  53,  54,  65,  66,  67,  68,  69, 122, 123, 124, 135, 136,\n",
       "             137, 138, 139, 192, 193, 194, 205, 206, 207, 208, 209, 262, 263,\n",
       "             264, 274, 275, 276, 277, 278, 331, 332, 333, 343, 344, 345, 346,\n",
       "             347, 400, 401, 402, 411, 412, 413, 414, 415, 468, 469, 478, 479,\n",
       "             480, 481, 482, 535, 544, 545, 546, 547, 548, 549, 602, 611, 612,\n",
       "             613, 614, 615, 616, 667, 678, 679, 680, 681, 682, 683, 733, 745,\n",
       "             746, 747, 748, 749, 750],\n",
       "            dtype='int64'),\n",
       " 'Vietnam': Int64Index([39, 109, 179, 249, 318, 388, 456, 523, 590, 657, 724, 793], dtype='int64')}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only take the country and recovered column, drop NAN values\n",
    "df = data_df[['Country/Region', 'Recovered']].dropna()\n",
    "# group the rows into countries\n",
    "sorted_df = df.groupby('Country/Region')\n",
    "sorted_df.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country/Region\n",
       "Malaysia                   0.0\n",
       "Spain                      0.0\n",
       "South Korea                0.0\n",
       "Singapore                  0.0\n",
       "Russia                     0.0\n",
       "Philippines                0.0\n",
       "Nepal                      0.0\n",
       "United States              0.0\n",
       "UK                         0.0\n",
       "Sweden                     0.0\n",
       "Macau                      0.0\n",
       "Italy                      0.0\n",
       "India                      0.0\n",
       "Hong Kong                  0.0\n",
       "Germany                    0.0\n",
       "France                     0.0\n",
       "Finland                    0.0\n",
       "Canada                     0.0\n",
       "Cambodia                   0.0\n",
       "Belgium                    0.0\n",
       "United Arab Emirates       0.0\n",
       "Taiwan                     0.0\n",
       "Sri Lanka                  1.0\n",
       "Vietnam                   12.0\n",
       "Japan                     26.0\n",
       "Australia                 30.0\n",
       "Thailand                 117.0\n",
       "Mainland China          8448.0\n",
       "Name: Recovered, dtype: float64"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum up all the recovered values for each country\n",
    "recovered_df = sorted_df['Recovered'].agg(np.sum)\n",
    "sorted_df = recovered_df.sort_values()\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thailand'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_df = sorted_df.nlargest(n=2)\n",
    "n_df.idxmin()\n",
    "#ans is Thailand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 / 6\n",
    "Create a dictionary which maps the ​Country/Region​ to the continent it is a member of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_continent(str):\n",
    "    dict = {'Asia': ('Mainland China', 'Singapore', 'Thailand','Japan', 'Hong Kong', 'South Korea',\n",
    "                     'Malaysia', 'Taiwan', 'Macau', 'Vietnam', 'United Arab Emirates', 'India', \n",
    "                     'Philippines', 'Russia', 'Cambodia', 'Nepal', 'Sri Lanka'),\n",
    "            'Africa': ('Ivory Coast'),\n",
    "            'Europe': ('Germany', 'France', 'Italy', 'UK', 'Belgium', 'Finland', 'Spain', 'Sweden'),\n",
    "            'North America': ('Canada', 'United States'),\n",
    "            'South America': ('Mexico', 'Brazil', 'Colombia'),\n",
    "            'Australia': ('Australia')\n",
    "            }\n",
    "    for continent, country in dict.items():\n",
    "        if str in country:\n",
    "            print(continent)\n",
    "            return continent\n",
    "    return np.nan;  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Australia\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Australia'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_continent('Australia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7\n",
    "Add a column called ‘​Continent​’ which uses the mapping from Problem 4 to match theCountry/Region​ to the continent it is from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Suspected</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 16:43</td>\n",
       "      <td>16678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>538.0</td>\n",
       "      <td>479.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 13:23</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Zhejiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:13</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:03</td>\n",
       "      <td>764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hunan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:23</td>\n",
       "      <td>661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1872</td>\n",
       "      <td>Heilongjiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Japan</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1876</td>\n",
       "      <td>Washington</td>\n",
       "      <td>United States</td>\n",
       "      <td>1/21/2020</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1877 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Province/State  Country/Region   Last Update  Confirmed  Suspected  \\\n",
       "0             Hubei  Mainland China  2/5/20 16:43    16678.0        NaN   \n",
       "1         Guangdong  Mainland China  2/5/20 13:23      895.0        NaN   \n",
       "2          Zhejiang  Mainland China  2/5/20 15:13      895.0        NaN   \n",
       "3             Henan  Mainland China  2/5/20 15:03      764.0        NaN   \n",
       "4             Hunan  Mainland China  2/5/20 15:23      661.0        NaN   \n",
       "...             ...             ...           ...        ...        ...   \n",
       "1872   Heilongjiang  Mainland China     1/21/2020        NaN        1.0   \n",
       "1873            NaN           Japan     1/21/2020        1.0        NaN   \n",
       "1874            NaN        Thailand     1/21/2020        2.0        NaN   \n",
       "1875            NaN     South Korea     1/21/2020        1.0        NaN   \n",
       "1876     Washington   United States     1/21/2020        1.0        NaN   \n",
       "\n",
       "      Recovered  Death  \n",
       "0         538.0  479.0  \n",
       "1          49.0    0.0  \n",
       "2          78.0    0.0  \n",
       "3          47.0    2.0  \n",
       "4          54.0    0.0  \n",
       "...         ...    ...  \n",
       "1872        NaN    NaN  \n",
       "1873        NaN    NaN  \n",
       "1874        NaN    NaN  \n",
       "1875        NaN    NaN  \n",
       "1876        NaN    NaN  \n",
       "\n",
       "[1877 rows x 7 columns]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data_df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to suppress output\n",
    "%%capture\n",
    "for reg in df['Country/Region']:\n",
    "    cont = get_continent(reg)\n",
    "    df.loc[(df['Country/Region'] == reg), 'Continent'] = cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Last Update</th>\n",
       "      <th>Confirmed</th>\n",
       "      <th>Suspected</th>\n",
       "      <th>Recovered</th>\n",
       "      <th>Death</th>\n",
       "      <th>Continent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Hubei</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 16:43</td>\n",
       "      <td>16678.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>538.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Guangdong</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 13:23</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Zhejiang</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:13</td>\n",
       "      <td>895.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Henan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:03</td>\n",
       "      <td>764.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Hunan</td>\n",
       "      <td>Mainland China</td>\n",
       "      <td>2/5/20 15:23</td>\n",
       "      <td>661.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Asia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Province/State  Country/Region   Last Update  Confirmed  Suspected  \\\n",
       "0          Hubei  Mainland China  2/5/20 16:43    16678.0        NaN   \n",
       "1      Guangdong  Mainland China  2/5/20 13:23      895.0        NaN   \n",
       "2       Zhejiang  Mainland China  2/5/20 15:13      895.0        NaN   \n",
       "3          Henan  Mainland China  2/5/20 15:03      764.0        NaN   \n",
       "4          Hunan  Mainland China  2/5/20 15:23      661.0        NaN   \n",
       "\n",
       "   Recovered  Death Continent  \n",
       "0      538.0  479.0      Asia  \n",
       "1       49.0    0.0      Asia  \n",
       "2       78.0    0.0      Asia  \n",
       "3       47.0    2.0      Asia  \n",
       "4       54.0    0.0      Asia  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8\n",
    "According to the data found in the “2019_nCoV_20200121_20200206.csv” file, what are thetotal number​ of ​confirmed ​cases of 2019 nCoV in each continent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Africa': Int64Index([1411], dtype='int64'),\n",
       " 'Asia': Int64Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "             ...\n",
       "             1860, 1862, 1863, 1864, 1866, 1867, 1870, 1873, 1874, 1875],\n",
       "            dtype='int64', length=1438),\n",
       " 'Australia': Int64Index([  42,   43,   44,   46,  112,  113,  114,  116,  182,  183,  184,\n",
       "              186,  252,  253,  255,  256,  321,  322,  324,  325,  390,  391,\n",
       "              393,  394,  458,  459,  461,  462,  525,  526,  528,  529,  592,\n",
       "              593,  595,  596,  658,  659,  661,  668,  725,  726,  728,  734,\n",
       "              801,  802,  803,  804,  856,  858,  863,  927,  928,  929,  986,\n",
       "              987,  988, 1044, 1045, 1046, 1099, 1100, 1151, 1152, 1205, 1206,\n",
       "             1257, 1258, 1308, 1309, 1360, 1361, 1412, 1413, 1457, 1505, 1551,\n",
       "             1596, 1640, 1684],\n",
       "            dtype='int64'),\n",
       " 'Europe': Int64Index([  35,   40,   48,   51,   55,   59,   62,   64,  105,  110,\n",
       "             ...\n",
       "             1353, 1362, 1405, 1456, 1504, 1550, 1595, 1639, 1683, 1727],\n",
       "            dtype='int64', length=124),\n",
       " 'North America': Int64Index([  47,   52,   53,   54,   57,   58,   65,   66,   67,   68,\n",
       "             ...\n",
       "             1632, 1633, 1676, 1677, 1720, 1721, 1760, 1797, 1843, 1876],\n",
       "            dtype='int64', length=204)}"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df[['Continent', 'Confirmed']].dropna()\n",
    "sorted_df = new_df.groupby('Continent')\n",
    "sorted_df.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Continent\n",
       "Africa                1.0\n",
       "Asia             304984.0\n",
       "Australia           238.0\n",
       "Europe              395.0\n",
       "North America       273.0\n",
       "Name: Confirmed, dtype: float64"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_df = sorted_df['Confirmed'].agg(np.sum)\n",
    "cont_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
